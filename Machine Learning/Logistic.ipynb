{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91961db1-7431-4764-9575-d90725853b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ca9521a-d46d-4d4b-9670-76872377f0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score \n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99ce136-8bab-4c35-acc9-7de31a0ffc0c",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e180ad2-378a-4345-827b-5057787273cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'final_challenge_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Read the cleaned CSV file\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m fraud_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal_challenge_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Display the first few rows\u001b[39;00m\n\u001b[1;32m      5\u001b[0m fraud_data\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'final_challenge_data.csv'"
     ]
    }
   ],
   "source": [
    "# Read the cleaned CSV file\n",
    "fraud_data = pd.read_csv('final_challenge_data.csv')\n",
    "\n",
    "# Display the first few rows\n",
    "fraud_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c622bff-fe9b-4532-8f8e-314b8cdefef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3158c0-71d2-428e-8999-690a9e29e6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subsetting missing fraud_bool\n",
    "\n",
    "missing_bool = fraud_data[fraud_data['fraud_bool'].isna()].copy()\n",
    "fraud_data = fraud_data.dropna(subset=['fraud_bool'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6d1580-1119-4300-a281-37e04b487d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3845dbe3-6773-405d-ac9c-68b483d1e39e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "missing = fraud_data.isna().sum()/ len(fraud_data)*100\n",
    "missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d4a0e7-ffe7-4dd5-a1de-e064a35c7dd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(fraud_data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfcab4b-591f-435b-81ea-264a2f440f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_cols = fraud_data.select_dtypes(include='int').columns\n",
    "fraud_data[int_cols] = fraud_data[int_cols].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbbae25-eaf7-4d8a-9070-558fa3e3ea80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(fraud_data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fb1141-7c85-46a9-8c2d-1651c3392032",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_data = fraud_data.drop(['credit_limit_to_salary'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1d936f-689c-4b0b-a199-065d6085f45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_prop = pd.crosstab(index = fraud_data['fraud_bool'], columns = \"prop\")/pd.crosstab(index = fraud_data['fraud_bool'], columns = \"prop\").sum()\n",
    "print(fraud_prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a21d083-d4a2-4143-830c-78496159d35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(index = fraud_data['fraud_bool'], columns = \"count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52db306-7f22-4c50-b446-19924efb0313",
   "metadata": {},
   "source": [
    "## Creating Test/Train & Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a208fe0-b727-48e3-9bad-bbe48a885f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_o = fraud_data.groupby(\"fraud_bool\").sample(n = 6800, random_state = 6)\n",
    "\n",
    "test_o = fraud_data.loc[fraud_data.index.difference(train_o.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50ad243-66f9-4aa1-af7c-b1d0233b2928",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(index = train_o['fraud_bool'], columns = \"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7103129b-b202-4d91-a47a-4ba1618211c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(index = test_o['fraud_bool'], columns = \"count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e3abea-735a-45a5-8492-3fedf68f2545",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994e8e0d-427d-4082-a84a-ba35e0919d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Income Column\n",
    "\n",
    "#Creating a flag column for income \n",
    "train_o['income_missing'] = train_o['income'].isna().astype(int)\n",
    "\n",
    "#filling missing income columns with salary. Have to convert salary to quantiles first\n",
    "train_o['salary_decile'] = pd.qcut(train_o['salary'], q=10, labels=[0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]).astype(float)\n",
    "train_o['income'] = train_o['income'].fillna(train_o['salary_decile'])\n",
    "train_o.drop(columns='salary_decile', axis=1, inplace=True)\n",
    "\n",
    "train_o.drop(columns='salary', axis=1, inplace=True)\n",
    "train_o = train_o.dropna(subset=['income'])\n",
    "train_o['income'] = train_o['income'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55de690f-07e9-4dc9-b821-22d76d6b76a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip_count_4w Column \n",
    "\n",
    "# Locating rows where 'zip_count_4w' contains a hyphen, flagging, then imputing with -1\n",
    "bad_zip = train_o['zip_count_4w'].str.contains('-', na=False)\n",
    "train_o['zip_count_4w_flag'] = bad_zip\n",
    "train_o.loc[bad_zip, 'zip_count_4w'] = -1\n",
    "train_o['zip_count_4w'] = train_o['zip_count_4w'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac3d524-2baa-4d9d-8ecf-166286e30373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Velocity Columns \n",
    "\n",
    "# Flag missing values\n",
    "train_o['velocity_6h_missing'] = train_o['velocity_6h'].isna().astype(int)\n",
    "train_o['velocity_24h_missing'] = train_o['velocity_24h'].isna().astype(int)\n",
    "train_o['velocity_4w_missing'] = train_o['velocity_4w'].isna().astype(int)\n",
    "\n",
    "# Impute with median\n",
    "med_vel_6h = train_o['velocity_6h'].median()\n",
    "train_o['velocity_6h'] = train_o['velocity_6h'].fillna(med_vel_6h)\n",
    "\n",
    "med_vel_24h = train_o['velocity_24h'].median()\n",
    "train_o['velocity_24h'] = train_o['velocity_24h'].fillna(med_vel_24h)\n",
    "\n",
    "med_vel_4w = train_o['velocity_4w'].median()\n",
    "train_o['velocity_4w'] = train_o['velocity_4w'].fillna(med_vel_4w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a2b11c-0431-46bf-a268-37fd07a967fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "missing = train_o.isna().sum()/ len(train_o)*100\n",
    "missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7fd0b0-1ab6-408d-b79e-79d3a08e7299",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_o['zip_count_4w_flag'] = train_o['zip_count_4w_flag'].astype('float64')\n",
    "\n",
    "\n",
    "int_cols = train_o.select_dtypes(include='int').columns\n",
    "train_o[int_cols] = train_o[int_cols].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfddc5f8-e370-4b53-b9bb-a6568db3283f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(train_o.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc03badc-bd61-405a-9765-c6ce2004b897",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = train_o.drop(columns=['fraud_bool'])\n",
    "predictors = pd.get_dummies(predictors, drop_first=True)\n",
    "predictors = predictors.astype(float)\n",
    "\n",
    "X = predictors\n",
    "y = train_o['fraud_bool']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b028d7ed-dba2-4e22-a50c-2563c569ee79",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017fa921-e95f-4d46-a771-b34b4b889318",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bf59e1-ca96-4435-9681-2bf69ec34c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Low Variability – Numeric\n",
    "fraud_data_num = fraud_data.select_dtypes(include = ['number'])\n",
    "non_flag_cols = [col for col in fraud_data_num.columns if not col.endswith(('_missing', '_OutOfRange', '_flagged'))]\n",
    "\n",
    "#variance threshold\n",
    "threshold = 0.01\n",
    "selector = VarianceThreshold(threshold = threshold)  \n",
    "selector.fit(fraud_data_num[non_flag_cols])\n",
    "\n",
    "# Get list of all column names\n",
    "flag = selector.get_support() \n",
    "all_features = fraud_data_num[non_flag_cols].columns \n",
    "low_variability_features = all_features[~flag] \n",
    "print(low_variability_features.tolist()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f2b6cf-0032-42eb-9d23-a5ea630e20dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Low Variability – Categorical\n",
    "\n",
    "for col in fraud_data.select_dtypes(include = 'object'): \n",
    "    top_freq = fraud_data[col].value_counts(normalize = True).iloc[0] #Loop through each categorical variable, counting each occurance of each unique value \n",
    "                                                            \n",
    "    if top_freq > 0.95: #Categorical variable with 1 category > 95% of the data considered for removal \n",
    "        print(f\"{col} ({top_freq:.1%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b907e846-8f45-464c-990b-7eeb149c8b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(['source_TELEAPP'],axis=1)\n",
    "X = X.drop(['source_UNKNOWN'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d217d16-db54-4a82-90e6-a813ddbee29e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Separate categorical (dummy) vs. continuous features\n",
    "categorical_features = [col for col in X.columns if X[col].nunique() == 2]\n",
    "continuous_features = [col for col in X.columns if X[col].nunique() > 2]\n",
    "\n",
    "X_cat = X[categorical_features]\n",
    "X_cont = X[continuous_features]\n",
    "\n",
    "# Fit SelectKBest for categorical variables\n",
    "selector = SelectKBest(score_func=chi2, k='all')  # 'all' keeps all features for scoring\n",
    "selector.fit(X_cat, y)\n",
    "\n",
    "# Correct closing syntax for DataFrame\n",
    "scores_cat_df = pd.DataFrame({\n",
    "    'Feature': X_cat.columns,\n",
    "    'Chi2_score': selector.scores_,\n",
    "    'p_value': selector.pvalues_\n",
    "})\n",
    "\n",
    "# Filter for features with p-value < 0.002\n",
    "selected_cat_features = scores_cat_df[scores_cat_df['p_value'] < 0.002]['Feature']\n",
    "\n",
    "# Sort results for better readability\n",
    "scores_cat_df = scores_cat_df.sort_values(by='Chi2_score', ascending=False)\n",
    "\n",
    "# Display top categorical features\n",
    "print(scores_cat_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1c7649-dd03-4566-9e45-921cebf12e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit SelectKBest for Continous Variables\n",
    "selector = SelectKBest(score_func=f_classif, k='all')  # 'all' keeps all features for scoring\n",
    "selector.fit(X_cont, y)\n",
    "\n",
    "# Create a DataFrame with feature names, F-scores, and p-values\n",
    "scores_cont_df = pd.DataFrame({\n",
    "    'Feature': X_cont.columns,\n",
    "    'F_score': selector.scores_,\n",
    "    'p_value': selector.pvalues_\n",
    "})\n",
    "\n",
    "# Filter for features with p-value < 0.002\n",
    "selected_cont_features = scores_cont_df[scores_cont_df['p_value'] < 0.002]['Feature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d92ae9-3392-4adc-a256-34f53781b565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame with only those selected columns\n",
    "X_reduced = X[selected_cat_features.tolist() + selected_cont_features.tolist()]\n",
    "\n",
    "X_reduced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e39c83-11ae-4624-aa40-e20860f765e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_quasi_complete_separation(X, y):\n",
    "    \"\"\"\n",
    "    Checks each categorical predictor in X for quasi-complete separation with respect to binary target y.\n",
    "    \n",
    "    Parameters:\n",
    "    - X: pd.DataFrame of predictors (categorical variables)\n",
    "    - y: pd.Series of binary target variable (e.g., 0/1 or True/False)\n",
    "    \n",
    "    Returns:\n",
    "    - List of variable names that exhibit quasi-complete separation\n",
    "    \"\"\"\n",
    "    problematic_vars = []\n",
    "\n",
    "    for col in X.columns:\n",
    "        ct = pd.crosstab(X[col], y)\n",
    "\n",
    "        # Check if any category (row) has a zero in any outcome class\n",
    "        if (ct == 0).any(axis=1).any():\n",
    "            print(f\"Quasi-complete separation detected in '{col}'\")\n",
    "            print(ct)\n",
    "            print()\n",
    "            problematic_vars.append(col)\n",
    "\n",
    "    return problematic_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36245bd3-0d04-43cf-88b4-64ba387723bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame with only those selected columns\n",
    "X_cat_reduced = X_reduced[selected_cat_features.tolist()]\n",
    "\n",
    "problem_vars = check_quasi_complete_separation(X_cat_reduced, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0107c102-b1a9-4736-b59d-903b1436824f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced = X_reduced.drop(problem_vars, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f1c164-9054-418d-bda5-ce7ce2b422cf",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb530c16-d78b-44ce-b7ff-176dff4b7853",
   "metadata": {},
   "source": [
    "### Initial Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fb547d-7ec2-410c-87b6-7e218e66687d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_o.shape)\n",
    "print(X_reduced.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5158fc57-5409-421c-acc7-8480b9600863",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Based on undersampling\n",
    "weight_1 = 1\n",
    "weight_0 = (1018338/11334) / (6800/6800)\n",
    "\n",
    "print(weight_0, weight_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65636479-f8c8-41c8-b2d3-f6b2b6f6bdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_o['weight'] = train_o.fraud_bool.replace({1: weight_1, 0: weight_0}).astype(float)\n",
    "\n",
    "X = sm.add_constant(X_reduced)\n",
    "\n",
    "model_1 = sm.GLM(y, X, family = sm.families.Binomial(), freq_weights = train_o['weight'])\n",
    "result_1 = model_1.fit()\n",
    "print(result_1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57237cc1-a11a-4e0a-b0f6-7c8fdc4d6a3c",
   "metadata": {},
   "source": [
    "### Stepwise Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf38fa0d-0dcc-4d7e-9511-634e6cc6f4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_reduced)\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X_reduced.columns)\n",
    "\n",
    "# Model\n",
    "logr = LogisticRegression(max_iter = 1000, solver = 'newton-cg', penalty = None) \n",
    "\n",
    "# Stepwise selection to find best subset of features\n",
    "sfs = SFS(logr,\n",
    "          k_features = \"best\", \n",
    "          forward = True,\n",
    "          floating = True,\n",
    "          scoring = 'roc_auc',\n",
    "          cv = 10)\n",
    "\n",
    "sfs = sfs.fit(X_scaled_df, y)\n",
    "\n",
    "# Get selected feature names\n",
    "selected_features = list(sfs.k_feature_names_)\n",
    "print(\"Selected features:\", selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd12c09-8567-4900-9ef7-c822b15029a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_stepwise = X_reduced[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e9ab5d-ae1b-4d97-bd96-6273aff4a56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_o['weight'] = train_o.fraud_bool.replace({1: weight_1, 0: weight_0}).astype(float)\n",
    "\n",
    "X_stepwise = sm.add_constant(X_stepwise).copy()\n",
    "\n",
    "model_2 = sm.GLM(y, X_stepwise, family = sm.families.Binomial(), freq_weights = train_o['weight'])\n",
    "result_2 = model_2.fit()\n",
    "print(result_2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1daaa7d-9aa8-491f-88d4-4790fd708484",
   "metadata": {},
   "source": [
    "## Model Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2694eb9-9907-41c8-b004-58e40bc0917a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_selected = X_stepwise.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e8e669-96aa-4dc6-9a2d-337e1b548a45",
   "metadata": {},
   "source": [
    "### Calibration Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ded8a7-382e-4489-8242-3760f47bad38",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_o['pred_prob'] = result_2.predict(X_selected)\n",
    "\n",
    "# Compute calibration curve\n",
    "prob_true, prob_pred = calibration_curve(train_o['fraud_bool'], train_o['pred_prob'], \n",
    "                                         n_bins = 10, strategy = 'quantile')\n",
    "\n",
    "plt.figure(figsize = (6, 6))\n",
    "plt.plot(prob_pred, prob_true, marker = 'o', label = 'Calibration curve')\n",
    "plt.plot([0, 1], [0, 1], linestyle = '--', color = 'gray', label = 'Perfectly calibrated')\n",
    "plt.xlabel('Predicted probability')\n",
    "plt.ylabel('Observed frequency')\n",
    "plt.title('Calibration Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2cb3d1-b2bd-4892-be7e-fd3ddb62f822",
   "metadata": {},
   "source": [
    "### C-statistic (AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358f4875-15a5-406b-abb5-dfcb36784a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_o['pred_prob'] = result_2.predict()\n",
    "\n",
    "auc = roc_auc_score(y, train_o['pred_prob'])\n",
    "print(\"C-statistic (AUC):\", auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de175453-266a-401b-bc36-abab77226a62",
   "metadata": {},
   "source": [
    "### Somer's D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62715d1e-c7e7-402d-95f1-13bcb7a1c501",
   "metadata": {},
   "outputs": [],
   "source": [
    "somer_d = 2 * auc - 1\n",
    "print(\"Somer's D:\", somer_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd271ba-7091-4847-aa32-5c422933f860",
   "metadata": {},
   "source": [
    "### Classification Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f742aab-f9f4-4baa-b047-b5a9946620fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(train_o['fraud_bool'], train_o['pred_prob'])\n",
    "\n",
    "data = {'TPR': tpr, 'FPR': fpr, 'Cut-off': thresholds, 'Youden': tpr-fpr}\n",
    "youden = pd.DataFrame(data)\n",
    "\n",
    "youden.sort_values(by = ['Youden'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88c48d3-e5eb-4b0a-8736-23e6f7a1ec06",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_o['pred'] = train_o['pred_prob'].map(lambda x: 1 if x > 0.5 else 0) #How should we decide cutoff??\n",
    "\n",
    "pd.crosstab(train_o['fraud_bool'], train_o['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678901ed-4f45-4506-bf7f-0532c6d9781e",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = roc_auc_score(train_o['fraud_bool'], train_o['pred_prob'])\n",
    "\n",
    "plt.cla()\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {auc:.2f}\")\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")  # chance line\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852237a1-995d-4d4c-b964-70a77101f77c",
   "metadata": {},
   "source": [
    "### K-S Stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee58ea80-b872-4941-bbb8-7adee88b991f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(train_o['fraud_bool'], train_o['pred_prob'])\n",
    "\n",
    "# Create the Youden DataFrame\n",
    "youden = pd.DataFrame({\n",
    "    'Cut-off': thresholds,\n",
    "    'TPR': tpr,\n",
    "    'FPR': fpr,\n",
    "    'Youden': tpr - fpr\n",
    "})\n",
    "\n",
    "# Sort by Cut-off and rename\n",
    "youden = youden.sort_values(by='Cut-off', ascending=True)\n",
    "\n",
    "ks_stat = youden.rename(columns={'TPR': 'PR_T', 'FPR': 'PR_F'})\n",
    "ks_stat = ks_stat.melt(id_vars='Cut-off', var_name='PR', value_name='value')\n",
    "\n",
    "ks_val = (youden['TPR'] - youden['FPR']).max()\n",
    "ks_cutoff = youden.loc[(youden['TPR'] - youden['FPR']).idxmax(), 'Cut-off']\n",
    "\n",
    "# Plot\n",
    "plt.cla()\n",
    "sns.lineplot(x='Cut-off', y='value', hue='PR', data=ks_stat)\n",
    "plt.xlim(1, 0)\n",
    "\n",
    "plt.title(\"KS Plot (TPR vs. FPR)\")\n",
    "plt.grid(True)\n",
    "plt.axvline(x=ks_cutoff, linestyle='--', color='red', label=f'KS = {ks_val:.2f}')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de53f4c6-7e6b-4643-81d8-75401f464927",
   "metadata": {},
   "source": [
    "# Taking into account the cost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5c79f2-5b6b-4f58-b9ce-18f43415f86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking into account the cost \n",
    "from sklearn.metrics import roc_curve\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# True labels and predicted probabilities\n",
    "y_true = train_o['fraud_bool'].astype(int)\n",
    "y_score = train_o['pred_prob'].astype(float)\n",
    "\n",
    "# --- Business Costs ---\n",
    "C_FN = 1200                     # Cost of false negative (missed fraud)\n",
    "C_FP_values = np.arange(700, 1001, 100)  # Costs of false positive (700 → 1000)\n",
    "\n",
    "# --- Check for constant target ---\n",
    "if len(set(y_true)) < 2:\n",
    "    raise ValueError(\"y_true has only one class. Need both positive and negative samples.\")\n",
    "\n",
    "# --- Compute ROC ---\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_score)\n",
    "\n",
    "# --- Base counts ---\n",
    "total_pos = sum(y_true)\n",
    "total_neg = len(y_true) - total_pos\n",
    "\n",
    "# --- Build results ---\n",
    "results = pd.DataFrame({\n",
    "    'Threshold': thresholds,\n",
    "    'TPR': tpr,\n",
    "    'FPR': fpr\n",
    "})\n",
    "\n",
    "# Compute cost for each FP cost level\n",
    "for C_FP in C_FP_values:\n",
    "    results[f'Cost_FP{C_FP}'] = (\n",
    "        (C_FP * results['FPR'] * total_neg) + \n",
    "        (C_FN * (1 - results['TPR']) * total_pos)\n",
    "    )\n",
    "\n",
    "# --- Find best threshold for each FP cost ---\n",
    "best_thresholds = []\n",
    "for C_FP in C_FP_values:\n",
    "    col = f'Cost_FP{C_FP}'\n",
    "    idx_min = results[col].idxmin()\n",
    "    best_thresholds.append({\n",
    "        'C_FP': C_FP,\n",
    "        'Best_Threshold': results.loc[idx_min, 'Threshold'],\n",
    "        'Min_Cost': results.loc[idx_min, col],\n",
    "        'TPR': results.loc[idx_min, 'TPR'],\n",
    "        'FPR': results.loc[idx_min, 'FPR']\n",
    "    })\n",
    "\n",
    "best_df = pd.DataFrame(best_thresholds)\n",
    "\n",
    "print(\"✅ Optimal thresholds by false positive cost:\")\n",
    "print(best_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94b443a-2be5-4f05-a4bc-ebb0854872e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base line compared to adjusting for cost\n",
    "from sklearn.metrics import roc_curve\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Inputs ---\n",
    "y_true = train_o['fraud_bool'].astype(int)\n",
    "y_score = train_o['pred_prob'].astype(float)\n",
    "\n",
    "# --- Business Costs ---\n",
    "C_FN = 1200                        # Cost of missing a fraud\n",
    "C_FP_values = np.arange(700, 1001, 100)  # Cost range for false positives (700–1000)\n",
    "baseline_threshold = 0.5           # Your current operational cutoff\n",
    "\n",
    "# --- Checks ---\n",
    "if len(set(y_true)) < 2:\n",
    "    raise ValueError(\"y_true has only one class. Need both positive and negative samples.\")\n",
    "\n",
    "# --- ROC curve ---\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_score)\n",
    "total_pos = sum(y_true)\n",
    "total_neg = len(y_true) - total_pos\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'Threshold': thresholds,\n",
    "    'TPR': tpr,\n",
    "    'FPR': fpr\n",
    "})\n",
    "\n",
    "# --- Compute cost and baseline savings for each FP cost ---\n",
    "best_thresholds = []\n",
    "\n",
    "# Baseline performance at threshold 0.5\n",
    "baseline_idx = np.argmin(np.abs(thresholds - baseline_threshold))\n",
    "baseline_tpr = tpr[baseline_idx]\n",
    "baseline_fpr = fpr[baseline_idx]\n",
    "\n",
    "for C_FP in C_FP_values:\n",
    "    # Expected cost at each threshold\n",
    "    results[f'Cost_FP{C_FP}'] = (\n",
    "        (C_FP * results['FPR'] * total_neg) + \n",
    "        (C_FN * (1 - results['TPR']) * total_pos)\n",
    "    )\n",
    "    \n",
    "    # Baseline cost\n",
    "    baseline_cost = (\n",
    "        (C_FP * baseline_fpr * total_neg) + \n",
    "        (C_FN * (1 - baseline_tpr) * total_pos)\n",
    "    )\n",
    "    \n",
    "    # Find minimum cost\n",
    "    idx_min = results[f'Cost_FP{C_FP}'].idxmin()\n",
    "    min_cost = results.loc[idx_min, f'Cost_FP{C_FP}']\n",
    "    best_threshold = results.loc[idx_min, 'Threshold']\n",
    "    \n",
    "    # Savings = baseline_cost - min_cost\n",
    "    savings = baseline_cost - min_cost\n",
    "    \n",
    "    best_thresholds.append({\n",
    "        'C_FP': C_FP,\n",
    "        'Best_Threshold': best_threshold,\n",
    "        'Baseline_Cost': baseline_cost,\n",
    "        'Min_Cost': min_cost,\n",
    "        'Savings': savings,\n",
    "        'TPR': results.loc[idx_min, 'TPR'],\n",
    "        'FPR': results.loc[idx_min, 'FPR']\n",
    "    })\n",
    "\n",
    "best_df = pd.DataFrame(best_thresholds)\n",
    "\n",
    "# --- Display results ---\n",
    "print(\"✅ Optimal thresholds and cost savings vs baseline (threshold = 0.5):\\n\")\n",
    "print(best_df.round(2))\n",
    "\n",
    "# --- Plot cost curves ---\n",
    "plt.figure(figsize=(8, 5))\n",
    "for C_FP in C_FP_values:\n",
    "    plt.plot(results['Threshold'], results[f'Cost_FP{C_FP}'], label=f'FP cost {C_FP}')\n",
    "plt.axvline(baseline_threshold, color='gray', linestyle='--', label='Baseline = 0.5')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Expected Cost')\n",
    "plt.title('Expected Cost vs. Threshold (Cost-Sensitive ROC)')\n",
    "plt.legend()  # fixed from plt.lege\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0f87d5-3850-490c-aa31-49bb19cc4d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# --- True labels and predicted probabilities ---\n",
    "y_true = train_o['fraud_bool'].astype(int)\n",
    "y_score = train_o['pred_prob'].astype(float)\n",
    "\n",
    "# --- ROC curve for standard model (all thresholds) ---\n",
    "fpr_model, tpr_model, thresholds_model = roc_curve(y_true, y_score)\n",
    "auc_model = roc_auc_score(y_true, y_score)\n",
    "\n",
    "# --- Business cost setup ---\n",
    "C_FN = 1200   # Cost of false negative (missed fraud)\n",
    "C_FP = 820    # Cost of false positive (wrongly flagged as fraud)\n",
    "\n",
    "# --- Class counts ---\n",
    "total_pos = sum(y_true)\n",
    "total_neg = len(y_true) - total_pos\n",
    "\n",
    "# --- Compute total business cost for each threshold ---\n",
    "costs = (C_FP * fpr_model * total_neg) + (C_FN * (1 - tpr_model) * total_pos)\n",
    "\n",
    "# --- Identify optimal threshold minimizing total cost ---\n",
    "idx_min = np.argmin(costs)\n",
    "optimal_threshold = thresholds_model[idx_min]\n",
    "optimal_fpr = fpr_model[idx_min]\n",
    "optimal_tpr = tpr_model[idx_min]\n",
    "optimal_cost = costs[idx_min]\n",
    "\n",
    "# --- Print results ---\n",
    "print(\"✅ Cost-Optimized Threshold (C_FP = 820)\")\n",
    "print(f\"Optimal Threshold : {optimal_threshold:.4f}\")\n",
    "print(f\"True Positive Rate: {optimal_tpr:.4f}\")\n",
    "print(f\"False Positive Rate: {optimal_fpr:.4f}\")\n",
    "print(f\"Minimum Expected Cost: ${optimal_cost:,.2f}\")\n",
    "\n",
    "# --- Plot ROC curves ---\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Standard ROC curve\n",
    "plt.plot(fpr_model, tpr_model, label=f\"Model (AUC = {auc_model:.3f})\", color='blue')\n",
    "\n",
    "# Baseline threshold = 0.5 marker\n",
    "baseline_idx = np.argmin(np.abs(thresholds_model - 0.5))\n",
    "plt.scatter(\n",
    "    fpr_model[baseline_idx],\n",
    "    tpr_model[baseline_idx],\n",
    "    color='red',\n",
    "    label=f\"Baseline threshold = 0.5\",\n",
    "    zorder=5\n",
    ")\n",
    "\n",
    "# Cost-optimized threshold marker\n",
    "plt.scatter(\n",
    "    optimal_fpr,\n",
    "    optimal_tpr,\n",
    "    color='green',\n",
    "    label=f\"Cost-optimal threshold = {optimal_threshold:.3f} (C_FP = 820)\",\n",
    "    zorder=5\n",
    ")\n",
    "\n",
    "# Chance line\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
    "\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve with Cost-Optimized Threshold (C_FP = 820)\")\n",
    "# plt.legend(\"cost-Optimized Threshold (C_FP = 820)\n",
    "# Optimal Threshold : 0.3905\n",
    "# True Positive Rate: 0.8636\n",
    "# False Positive Rate: 0.2874\n",
    "# Minimum Expected Cost: $1,996,740.00\")\n",
    "\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aab8b3d-2288-4da1-aa17-7b270ef3a163",
   "metadata": {},
   "source": [
    "### Precision, Recall, & Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37af68c7-8d35-4366-8f2f-a3f257729022",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "precision = np.array([])\n",
    "recall = np.array([])\n",
    "accuracy = np.array([])\n",
    "f1score = np.array([])\n",
    "\n",
    "for y in range(100):\n",
    "    train_o['pred'] = train_o['pred_prob'].map(lambda x: 1 if x > y/100 else 0)\n",
    "    value_p = precision_score(train_o['fraud_bool'], train_o['pred'])\n",
    "    precision = np.append(precision, value_p)\n",
    "    value_r = recall_score(train_o['fraud_bool'], train_o['pred'])\n",
    "    recall = np.append(recall, value_r)\n",
    "    value_a = accuracy_score(train_o['fraud_bool'], train_o['pred'])\n",
    "    accuracy = np.append(accuracy, value_a)\n",
    "    value_f = f1_score(train_o['fraud_bool'], train_o['pred'])\n",
    "    f1score = np.append(f1score, value_f)\n",
    "\n",
    "data = {'Precision': precision, 'Recall': recall, 'Accuracy': accuracy, 'Cut-off': range(100), 'F1': f1score}\n",
    "f1_s = pd.DataFrame(data)\n",
    "\n",
    "f1_s.sort_values(by = ['F1'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063737f8-f718-4bc9-9b7d-f8a863b9f1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lift_and_gains(y_true, y_proba, n_bins=10):\n",
    "    \"\"\"\n",
    "    Plot Lift and Cumulative Gains curves.\n",
    "    \n",
    "    Parameters:\n",
    "    - y_true: array-like, true binary labels (0/1)\n",
    "    - y_proba: array-like, predicted probabilities for the positive class\n",
    "    - n_bins: number of bins/deciles to split data\n",
    "    \n",
    "    Returns:\n",
    "    - None (plots the curves)\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame({\n",
    "        'y_true': y_true,\n",
    "        'y_proba': y_proba\n",
    "    })\n",
    "    \n",
    "    # Sort descending by predicted probability\n",
    "    df = df.sort_values(by='y_proba', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    # Add cumulative counts\n",
    "    df['cum_total'] = np.arange(1, len(df) + 1)\n",
    "    df['cum_positives'] = df['y_true'].cumsum()\n",
    "    \n",
    "    total_positives = df['y_true'].sum()\n",
    "    total_samples = len(df)\n",
    "    \n",
    "    # Cumulative Gains: % positives captured vs % samples\n",
    "    df['cum_gains'] = df['cum_positives'] / total_positives\n",
    "    \n",
    "    # Lift: (cumulative gains) / (cumulative % of sample)\n",
    "    df['cum_lift'] = df['cum_gains'] / (df['cum_total'] / total_samples)\n",
    "    \n",
    "    # Sample points for plotting (deciles)\n",
    "    cutoffs = np.linspace(0, total_samples, n_bins + 1, dtype=int)\n",
    "    cutoffs = cutoffs[cutoffs > 0]  # remove zero\n",
    "    plot_points = df.loc[cutoffs - 1, ['cum_total', 'cum_gains', 'cum_lift']].copy()\n",
    "    plot_points['percent_samples'] = plot_points['cum_total'] / total_samples * 100\n",
    "    \n",
    "    # Plot\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # Plot Cumulative Gains\n",
    "    axes[0].plot(plot_points['percent_samples'], plot_points['cum_gains'], marker='o', color='blue', label='Cumulative Gains')\n",
    "    axes[0].plot([0, 100], [0, 1], linestyle='--', color='blue', alpha=0.5, label='Random Gains')\n",
    "    axes[0].set_xlabel('Percent of Sample')\n",
    "    axes[0].set_ylabel('Cumulative Gains')\n",
    "    axes[0].set_title('Cumulative Gains Curve')\n",
    "    axes[0].set_ylim(0, 1.05)\n",
    "    axes[0].grid(True)\n",
    "    axes[0].legend()\n",
    "    \n",
    "    # Plot Lift\n",
    "    axes[1].plot(plot_points['percent_samples'], plot_points['cum_lift'], marker='o', color='red', label='Lift')\n",
    "    axes[1].axhline(1, linestyle='--', color='red', alpha=0.5, label='Random Lift')\n",
    "    axes[1].set_xlabel('Percent of Sample')\n",
    "    axes[1].set_ylabel('Cumulative Lift')\n",
    "    axes[1].set_title('Cumulative Lift Curve')\n",
    "    axes[1].set_ylim(0, plot_points['cum_lift'].max() * 1.1)\n",
    "    axes[1].grid(True)\n",
    "    axes[1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f843d8-8b0f-4238-875a-e89c5e790214",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lift_and_gains(train_o['fraud_bool'], train_o['pred_prob'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db39acb7-eb43-4816-bf46-7fd19aaef390",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d706669-d3b0-43c6-98a4-57523130c9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols_test = test_o.select_dtypes(include='number').columns\n",
    "\n",
    "for col in num_cols_test:\n",
    "    if test_o[col].isnull().any():\n",
    "        # Create missing flag column\n",
    "        test_o[f'{col}_was_missing'] = test_o[col].isnull().astype(int)\n",
    "\n",
    "        # Impute with median\n",
    "        median = test_o[col].median()\n",
    "        test_o[col] = test_o[col].fillna(median)\n",
    "print(test_o.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422433ee-c56a-4180-a5b4-c5328c467300",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_test = test_o.drop(columns=['fraud_bool'])\n",
    "predictors_test = pd.get_dummies(predictors_test, drop_first=True)\n",
    "predictors_test = predictors_test.astype(float)\n",
    "\n",
    "X_test = predictors_test\n",
    "y_test = test_o['fraud_bool']\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fabb2ad-aa52-4b46-a2af-1feca71c85ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# --- Ensure test has all columns used in training ---\n",
    "missing_cols = set(selected_features) - set(X_test.columns)\n",
    "for col in missing_cols:\n",
    "    X_test[col] = 0  # fill missing dummy columns with 0\n",
    "\n",
    "# --- Reorder columns to match training exactly ---\n",
    "X_test1 = X_test[selected_features].copy()\n",
    "X_test1 = sm.add_constant(X_test1, has_constant='add')\n",
    "\n",
    "# --- Predict probabilities using weighted logistic model ---\n",
    "y_pred_prob = result_2.predict(X_test1)\n",
    "\n",
    "# --- Evaluate performance ---\n",
    "metrics = {\n",
    "    'MAE': mean_absolute_error(y_test, y_pred_prob),\n",
    "    'LogLoss': log_loss(y_test, y_pred_prob),\n",
    "    'BrierScore': brier_score_loss(y_test, y_pred_prob),\n",
    "    'ROC_AUC': roc_auc_score(y_test, y_pred_prob)\n",
    "}\n",
    "\n",
    "print(pd.Series(metrics).round(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cacd46b-68a8-4e59-9766-5d3630f6403f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Convert probabilities to binary predictions using best threshold ---\n",
    "best_threshold = 0.0072  # replace with your computed optimal threshold\n",
    "y_pred_binary = (y_pred_prob >= best_threshold).astype(int)\n",
    "\n",
    "# --- Compute metrics ---\n",
    "mae = mean_absolute_error(y_test, y_pred_prob)\n",
    "ll = log_loss(y_test, y_pred_prob)\n",
    "brier = brier_score_loss(y_test, y_pred_prob)\n",
    "accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "auc = roc_auc_score(y_test, y_pred_prob)\n",
    "recall = recall_score(y_test, y_pred_binary)\n",
    "\n",
    "# --- Display results ---\n",
    "print(f\"Best Threshold: {best_threshold:.2f}\")\n",
    "print(f\"Log Loss: {ll:.4f}\")\n",
    "print(f\"Brier Score: {brier:.4f}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"AUC: {auc:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_binary))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33f5fec-b246-45ae-bdcd-e0f93713e5e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178b2f97-6d81-4c49-89f6-8bff7819bee3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6864551-f1be-48f9-8d66-05175e846b6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9880297d-82bd-4856-818e-0c2e3b32ef62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
